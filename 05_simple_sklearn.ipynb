{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147eb64b-c163-4ae9-9f0c-ad83d9df831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Jupyter notebook style\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from custom.styles import style_string\n",
    "\n",
    "HTML(style_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed234e1-1a06-4249-8007-014067272bf9",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center;\">\n",
    "  <img src=\"custom/molssi_main_horizontal.png\" style=\"display: block; margin: 0 auto; max-height:200px;\">\n",
    "</div>\n",
    "\n",
    "# Introduction to Data Fitting with SciKitLearn\n",
    "\n",
    "<div class=\"overview admonition\"> \n",
    "<p class=\"admonition-title\">Overview</p>\n",
    "\n",
    "Questions:\n",
    "\n",
    "* How do I fit a model using SciKitLearn?\n",
    "\n",
    "* How can I use SciKitLearn to assess my model?\n",
    "\n",
    "* How can I use other models from the SciKitLearn library?\n",
    "\n",
    "Objectives:\n",
    "\n",
    "* Fit a linear model using SciKitLearn.\n",
    "    \n",
    "* Use train_test_split to split the data.\n",
    "\n",
    "* Try other models from SciKitLearn.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe50af1-d2fe-420d-b80e-899ba73576a2",
   "metadata": {},
   "source": [
    "## Data Loading and Visualization\n",
    "\n",
    "Before fitting our models, we will first load our data using pandas and visualize the linear relationships using seaborn.\n",
    "For a review of pandas and seaborn, see notebok `03_python_data_science`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab93004-76be-4486-bf7b-b36c68793f16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # for dataframes\n",
    "from rdkit.Chem import PandasTools # for loading dataframes from SDF files\n",
    "\n",
    "import seaborn as sns # for graphs\n",
    "\n",
    "PandasTools.RenderImagesInAllDataFrames(True)\n",
    "\n",
    "df = PandasTools.LoadSDF(\"data/amino_acids-data.sdf\", strictParsing=False, includeFingerprints=True, smilesName=\"SMILES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d9906e-0f11-4f5b-a690-2815d7035f61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(3) # preview the first three rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22900c5b-c109-4cda-b952-5ea71a976b6e",
   "metadata": {},
   "source": [
    "Unfortunately, `LoadSDF` doesn't always load data types correctly, as can be seen using `df.info`. \n",
    "We would expect `MolWt`, `TPSA`, and `NumHeavyAtoms` to be integers or float, but they are listed as \"object\".\n",
    "We can use the `apply` method to apply the pandas function `to_numeric` to every column. \n",
    "Adding the argument `errors=\"ignore\"` will make it skip the columns that can't be turned into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d3123-75a1-4bff-8226-3e1b0c1164b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498db58b-aaec-423b-81a9-61113a94f83d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.apply(pd.to_numeric, errors=\"ignore\") # convert columns to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d0e029-7970-426b-b28d-5239c6485771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.info() # Now our columns are numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e586cec-6773-4d66-bc6c-effe8007d52d",
   "metadata": {},
   "source": [
    "### Visualizing Correlation\n",
    "\n",
    "One way to visualize the relationship between different variables is to use a pandas correlation matrix.\n",
    "This is available on a dataframe using [df.corr()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html). \n",
    "This will return a dataframe that shows the correlation between each variable and every other variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b37c2-6963-4256-977d-28690f73583a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.corr(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c4bca-db83-4076-a0e9-02b0ad0bbc50",
   "metadata": {},
   "source": [
    "The correlation ranges from 0 (not correlated) to 1 (correlated). The correlation of a column with itself is 1.\n",
    "We can combine this with a heatmap function in seaborn to see this visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3f54a-5e7c-4759-98ec-8a2aeb96fcdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(numeric_only=True), cmap=\"Blues\", annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71555fb-589f-477b-a0d9-6f9f430f471e",
   "metadata": {},
   "source": [
    "## Fitting using SciKitLearn\n",
    "\n",
    "[Scikit-learn](https://scikit-learn.org/stable/index.html) is a popular machine learning library in Python that provides a wide range of algorithms for supervised and unsupervised learning, including classification, regression, clustering, and dimensionality reduction. It is built on top of NumPy, SciPy, and matplotlib, and provides a simple and efficient API for working with data in Python. \n",
    "\n",
    "For our simple example, we will fit a linear relationship between the number of heavy atoms and the molecular weight. As a reminder, the equation for a linear relationship is $y = mx + b$.\n",
    "Molecular weight and number of heavy atoms will obviously be correlated, but is a good demonstration of how to use the scikitlearn library.\n",
    "All model fits in Scikit-Learn use [a similar API](https://scikit-learn.org/stable/developers/develop.html#apis-of-scikit-learn-objects), so learning how to do a linear fit will directly translate to other models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa464a-42d1-4fc4-9018-dd1aa9c032a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression # import the linear regression model\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cde20-6620-4388-8c59-45a76fa06f14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get our x and y data\n",
    "X = df[[\"NumHeavyAtoms\"]]\n",
    "Y = df[[\"MolWt\"]]\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c547a-6839-4519-9faf-2f7791e5fd70",
   "metadata": {},
   "source": [
    "That's it! That is how we fit a SciKit Learn model to our data. \n",
    "Now, our variable `linear_model` is a trained SciKit Learn model.\n",
    "We can use it to predict new values or evaluate our model.\n",
    "\n",
    "First, we will look at the score for the model on our training data.\n",
    "This score will range from 0 to 1, with a value closer to 1 indicating a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f424de4c-f5fc-46ab-9720-5e15f2d82750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear_model.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0845aa02-6d93-4344-93a9-f1a5226daafd",
   "metadata": {},
   "source": [
    "Our model score is `0.96`. This indicates that our model is a good fit.\n",
    "\n",
    "Our trained model, `linear_model` now has a method called `predict`. \n",
    "If we put in values for our dependent variable, our model will return what values our model\n",
    "will predict.\n",
    "To visualize how well our model does, we will compare our model predicted values to our\n",
    "observed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31949038-9265-4af8-b5e8-a006e64cc44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the model to make predictions and add it to the graph\n",
    "model_values = linear_model.predict(X)\n",
    "\n",
    "# Save our predicted values in a new column in our dataframe.\n",
    "df[\"PredictedWt\"] = model_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ba416d-960f-4fa2-a0a9-a201506e2b1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf00ed-ca54-4750-8ef1-2ad1ce0faa90",
   "metadata": {},
   "source": [
    "We will now use seaborn to visualize our actual and predicted values.\n",
    "This plot shows the `MolWt` as the x value, with the predicted `MolWt` as the Y value.\n",
    "The `MolWt` vs itself is shown as a reference line. For a perfect model,\n",
    "all values would fall along the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472d904-99ae-4a1e-9f6a-825039a9f79c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"MolWt\", y=\"PredictedWt\", data=df)\n",
    "sns.lineplot(x=\"MolWt\", y=\"MolWt\", data=df, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c444b5-be32-4406-b925-af4f9bb400fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(Y, model_values)\n",
    "rmse = math.sqrt(mse)\n",
    "r2 = r2_score(Y, model_values)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77870035-63ef-4519-8e44-243c90fb0524",
   "metadata": {},
   "source": [
    "<div class=\"exercise admonition\">\n",
    "<p class=\"admonition-title\">Exercise</p>\n",
    "\n",
    "    Perform a linear fit with MolWt as the y value and TPSA as the x value. Repeat the plotting and scoring analysis.\n",
    "\n",
    "</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2fc979-3921-4547-aa47-0c0890732a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19200145-90a8-4bc2-b1f8-14a0c9a5dd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa6b18-5923-417f-943e-140d1ab8f996",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af056eb5-1cc1-4250-9f09-43bdfeb31d0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b10bd43-a9cc-415f-b0bf-8e4b6535c3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541be77d-77ad-46cd-8ea4-3e0bfb66e5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b9ac7d4-0f91-433b-91b0-606b88f46391",
   "metadata": {},
   "source": [
    "<div class=\"exercise admonition\">\n",
    "<p class=\"admonition-title\">Exercise - Multilinear Regression\n",
    "\n",
    "<p> To perform multilinear regression, you only need to feed in two columns of data for X. Then, you perform the fit the same way. </p>\n",
    "    \n",
    "```python\n",
    "X = df[[\"MolWt\", \"TPSA\"]]\n",
    "```\n",
    "\n",
    "Now, you will be fitting an equation of the form $y = m_{1}x_{1} + m_{2}x_{2} +b$.  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d443de-9a46-4793-816a-ebfe386237c9",
   "metadata": {},
   "source": [
    "## Model Validation - Train Test Split\n",
    "\n",
    "When training a model for machine learning, it is a best practice to evaluate the model's performance on data that was not part of the training set.\n",
    "One way to achieve this is to use a method called \"train test split\".\n",
    "\n",
    "Train-test split is a widely used technique in the field of machine learning and data science to evaluate the performance of a model. It involves dividing the available data into two distinct sets: a training set and a testing set. This partitioning is essential to ensure that the model generalizes well to new, unseen data and to prevent overfitting.\n",
    "\n",
    "The primary purposes of using train-test split are:\n",
    "\n",
    "Model validation: To ensure that the model built using the training data performs well on unseen data, the testing set serves as a proxy for new data. By comparing the model's predictions with the actual outcomes in the testing set, we can gauge its predictive accuracy and robustness.\n",
    "\n",
    "Prevent overfitting: Overfitting occurs when a model learns to perform exceptionally well on the training data but fails to generalize to new data. This is usually due to the model capturing the noise or random fluctuations in the training data rather than the underlying patterns. A train-test split helps mitigate this issue by allowing us to evaluate the model's performance on a separate dataset.\n",
    "\n",
    "To perform a train-test split, the data is typically divided into approximately 70-80% for training and 20-30% for testing. This ratio can be adjusted depending on the size and characteristics of the dataset. The split should be done randomly to ensure that both sets are representative of the overall data distribution.\n",
    "\n",
    "SciKit-Learn has tools that can split your data for you. We will now use `train-test-split` and repeat our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba06ad-e406-4e9a-ad81-c1c2de980ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b466b3f-ed5f-4b20-bd29-a0d958e75b51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d337d-74fb-40a5-8729-c037cee0480c",
   "metadata": {},
   "source": [
    "Now we perform a fit using the training data only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba914e5-91cf-4613-af10-31cc1f807a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ttt_model = LinearRegression()\n",
    "ttt_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c600e-9297-444e-b991-02309dd22c13",
   "metadata": {},
   "source": [
    "After performing our fit with the training data, we use the \"test\" data to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5d492-26a8-4080-8f9e-87604f3071e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = ttt_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cad05-a160-42f4-a092-5c787e58177c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame()\n",
    "df_train[\"MolWt\"] = Y_test\n",
    "df_train[\"Predicted MolWt\"] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3f9f4-b203-49af-95e7-5cd5fa6b361a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"MolWt\", y=\"Predicted MolWt\", data =df_train)\n",
    "sns.lineplot(x=\"MolWt\", y=\"MolWt\", data=df, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9771f8c-8442-4eba-af60-2f5328397397",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(Y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "r2 = r2_score(Y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bc1e70-13c4-4812-b43f-108b0e1810c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare it to model performance on the training data.\n",
    "\n",
    "y_pred = ttt_model.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluate the model's performance\n",
    "mse = mean_squared_error(Y_train, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "r2 = r2_score(Y_train, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fd6c27-c1f1-45a9-b26f-53661f170b62",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## The SciKit Learn Model API\n",
    "\n",
    "All scikit learn models use the same API, or interface. This means to switch from a linear model to a more sophisticated model like a [random forest model](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), one need only change\n",
    "the model creation.\n",
    "\n",
    "For example, recall our code to fit a linear model and use it for prediction:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,Y)\n",
    "predictions = model.predict(X)\n",
    "```\n",
    "\n",
    "To do the same thing with a random forest regresso, the code would be:\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, Y)\n",
    "predictions = model.predict()\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "<div class=\"exercise admonition\">\n",
    "<p class=\"admonition-title\">Exercises - Challenge</p>\n",
    "\n",
    "<p> 1. Repeat this analysis for your vitamins data set.</p>\n",
    "    <p> 2. <strong>Bonus</strong> - Use the solvation dataset from the pandas lesson and create a model for solubility. You can use the descriptors in the file, or you can use RDKit to create molecules from the SMILES strings.</p>\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7969cdc-4f69-4a08-acb5-8904b1dd8c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ba860-2e0c-44b2-bbb3-88a7e65d70c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc2450-3040-443d-a963-2d87713db304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776307ef-4810-49cc-a5e2-ac04411062d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec245cde-99ee-4801-9a87-b4c762673a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
